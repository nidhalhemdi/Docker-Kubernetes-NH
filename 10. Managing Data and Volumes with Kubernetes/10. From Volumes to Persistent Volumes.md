# From Volumes to Persistent Volumes

You already learned how **basic Kubernetes volumes** work:

* They are defined *inside the Pod spec* (in the Deployment YAML).
* They attach storage *directly to a Pod*.
* Examples: `emptyDir`, `hostPath`, `nfs`, `awsElasticBlockStore`, etc.

Now this lecture explains **why basic volumes are not enough** and why Kubernetes introduces **Persistent Volumes (PVs)** and **Persistent Volume Claims (PVCs)**.

---

# â— The Problem With Regular Volumes

### 1. **Volumes disappear when Pods die**

If the Pod restarts or is replaced, the data is lost â€” unless you're using a storage type that persists externally.

### 2. **Volumes belong to a specific Pod**

Scaling from 1 Pod â†’ 2 Pods?
Some types (like `emptyDir`) mean the new Pod wonâ€™t see the data written by the old one.

### 3. **`hostPath` only works on a single-node cluster**

`hostPath` attaches data to one specific worker node.

With **minikube** (1 node), this works fine.
But in a real cluster (many nodes), Pods may land on *different* nodes â†’ the data would not follow them.

So regular volumes do **NOT** solve production-level storage problems.

---

# ğŸ‘‰ Why We Need Persistent Volumes (PVs)

Persistent Volumes solve all of the above issues because they are:

### âœ” **Independent from Pods**

Data stays even if Pods are deleted or recreated.

### âœ” **Independent from Nodes**

Data is not stored on a nodeâ€™s disk.
It typically lives in a cloud storage service (AWS EBS, Azure Disk, NFS, CSI, etc).

### âœ” **Created and managed separately**

You create storage **once** at the cluster level.

You donâ€™t redefine the volume in each Podâ€™s YAML file.

---

# â­ Core Idea: PV + PVC Architecture

Kubernetes introduces TWO new objects:

---

## **1. Persistent Volume (PV)**

* A cluster-wide storage resource
* Created by administrators (or dynamically provisioned)
* Lives independently of Pods
* Has a type like:

  * AWS EBS
  * Azure Disk
  * NFS
  * CSI (very flexible)

The storage physically exists **outside** the cluster nodes.

---

## **2. Persistent Volume Claim (PVC)**

* A request for storage by a Pod
* A Pod â€œclaimsâ€ an existing PV
* Describes what it needs:

  * size (e.g., 5Gi)
  * access mode (ReadWriteOnce, ReadWriteMany)
  * storage class (optional)

Pods do **not** attach to PVs directly.
They attach to PVCs â†’ which then bind to PVs.

---

# ğŸ“Œ Why This Is Better

### Before (simple volumes):

Pod â†’ Volume (defined in Pod YAML)

### With PV/PVC:

Pod â†’ PVC â†’ PV â†’ Storage backend

This gives:

âœ” Data that survives Pod replacement
âœ” Data that survives scaling
âœ” Data not tied to any specific node
âœ” Clean separation between â€œstorage adminâ€ and â€œapplication developerâ€

---

# â­ Example Use Case

### If you run:

* A database container
* An uploads folder
* A file-based cache
* Any long-term application data

â†’ You **must** use Persistent Volumes.

---

# ğŸŒ Real Deployment Example

For AWS:

* PV might use **AWS EFS** or **AWS EBS**
* And you would connect it using the **EFS CSI driver**

Thatâ€™s why the previous lecture about CSI is important â€” CSI is the modern way to attach real storage systems to Kubernetes.

---

# ğŸ§ª For Local Development (Minikube)

Since minikube is **1 node**, you can use:

* `hostPath` for testing PVs locally
  (even though it is *not* valid for real production clusters)

This lets you learn how PV and PVC work *without* needing a cloud provider.

---

# âœ” Summary

1. Regular volumes â†’ tied to Pods â†’ data disappears or is node-dependent
2. Persistent Volumes â†’ cluster-level storage, independent of Pods & Nodes
3. PVCs â†’ Pods request storage via a claim
4. PVs + PVCs â†’ scalable, safe, production-ready storage architecture
5. Local testing uses `hostPath`, but real clusters use cloud storage or CSI
