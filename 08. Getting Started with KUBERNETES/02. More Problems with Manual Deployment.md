# **More Problems with Manual Deployment**

## **1. What Kubernetes Is — in simple terms**

* Kubernetes is *not* a single piece of software.
* It’s **a system / framework / collection of tools** for:

  * **Automating deployment**
  * **Automating scaling**
  * **Automating management (self-healing)**
    of containerized applications.

Its purpose: solve the *pain* and *limits* of manually deploying containers on servers.

---

# **2. Problems with manual container deployment (why Kubernetes exists)**

## **Problem 1 — You must manage your own servers**

Example: creating EC2 machines → install Docker → run containers manually.

Issues:

* You must maintain OS & security patches.
* You must install/update Docker yourself.
* You need to configure everything by hand.

(These challenges are real, but **not even the main focus here**.)

---

## **Problem 2 — Containers can crash and no one replaces them**

Containers can fail because:

* The app encounters an error
* Memory leaks
* Temporary network failure
* Internal bug
* Host-level issue

If a container crashes:

* Your app becomes unavailable.
* With manual deployment:

  * **You must watch logs yourself.**
  * **You must restart containers yourself.**
  * You cannot do that 24/7.

This is unacceptable for any serious application.

---

## **Problem 3 — No automatic scaling**

Real apps must scale:

* **Scale UP** when traffic or workload increases
  (more requests, more data to process).
* **Scale DOWN** when traffic decreases
  (to save money or resources).

Manual workflow:

* Log into the server
* Start extra containers or kill containers
* Manage load balancing manually

This becomes impossible as traffic changes dynamically.

---

## **Problem 4 — Traffic load balancing**

If multiple containers run the same app:

* You must route traffic **evenly** across them.
* Otherwise:

  * One container gets overloaded
  * Others sit idle
  * Performance becomes unpredictable

Manual load balancing is:

* Hard
* Error-prone
* Requires extra tools (NGINX, HAProxy, AWS ALB, etc.)
* Not dynamically updated when containers crash or get recreated

---

## **Problem 5 — Workload-based scaling (not only for web apps)**

Some containers do batch work:

* Image processing
* File conversions
* Long-running jobs

If more tasks arrive, you may need more containers running the same job.

Manual scaling becomes:

* Too slow
* Too complex
* Repetitive

---

# **3. Why you need a system like Kubernetes**

Because manually:
❌ You cannot monitor failing containers 24/7
❌ You cannot manually restart containers
❌ You cannot manually scale up/down fast enough
❌ You cannot manage load balancing dynamically
❌ You cannot efficiently operate real-world systems

Kubernetes solves all of this by:

* **Self-healing** (auto restarts failed containers)
* **Auto-scaling**
* **Automated deployments**
* **Service-level load balancing**
* **Declarative desired state** (“I want 3 containers” → k8s guarantees it)

---

# **4. Key Takeaways (super concise)**

* Manual container deployments don’t scale.
* You need automated:

  * Recovery
  * Scaling
  * Scheduling
  * Load balancing
* Kubernetes provides all of this as one unified system.

---

# **5. Practical Tips / Mental Model**

* Think of Kubernetes as **an automated babysitter + conductor** for your containers.
* You define **what you want** (e.g., “run 4 instances of this app”).
  Kubernetes ensures **reality matches your wish**.
* Stop thinking in “run Docker container manually”
  and start thinking in **desired state**.

---

# **6. Useful commands (contextual, even though not in lecture)**

When managing containers manually, you'd run things like:

```bash
docker run -d myapp
docker stop <container>
docker logs <container>
docker ps
```

All of these become **obsolete** (or handled automatically) once using Kubernetes.
